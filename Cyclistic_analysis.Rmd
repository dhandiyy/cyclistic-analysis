---
title: "Cyclistic Analysis"
author: "Dhandi Yudhit Yuniar"
date: "2023-08-20"
output:
  html_document: default
  pdf_document: default
---

**Studi kasus ini dikerjakan untuk menyelesaikan tugas Capstone Project in Google Data Analytics Certificate - [Coursera](https://www.coursera.org/programs/proa-analitik-data-google-o8klv/professional-certificates/analitik-data-google?collectionId=skill~data-analysis)**

(Masih dalam tahap pengerjaan dan belum selesai)

# Latar Belakang

Cyclistic merupakan sebuah perusahaan fiksi yang bergerak dibidang penyewaan/berbagi sepeda di Chicago, memiliki 5.824 armada sepeda dan 692 stasiun di seluruh Chicago. Cyclistic menawarkan tiket sekali jalan, tiket sehari penuh, dan keanggotaan tahunan. Pelanggan yang membeli tiket sekali jalan atau tiket sehari penuh disebut sebagai [pengendara kasual]{.underline}. Pelanggan yang membeli keanggotaan tahunan adalah [anggota tahunan]{.underline}.

Saya adalah seorang analis data junior yang bekerja di tim analis pemasaran di Cyclistic. Direktur pemasaran percaya bahwa kesuksesan perusahaan di masa depan tergantung pada upaya untuk **memaksimalkan jumlah keanggotaan tahunan**. Oleh karena itu, tim saya ingin memahami bagaimana pengendara kasual dan anggota tahunan menggunakan sepeda Cyclistic secara berbeda. Dari wawasan ini, tim saya akan merancang strategi pemasaran baru untuk mengubah pengendara biasa menjadi anggota tahunan.

Dalam menyelesaikan tugas bisnis yang diberikan saya menggunakan kerangka kerja yang telah saya pelajari di Coursera sebagai Data Analysis.

#### **Kerangka Kerja**

+-------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| Proses Analisi Data                                                                 | Tugas                                                                                                                    |
+=====================================================================================+==========================================================================================================================+
| **Bertanya**                                                                        | 1.  Membuat dokumen lingkup kerja (SOW)                                                                                  |
|                                                                                     |                                                                                                                          |
| Pemahaman tentang projek dan ekspektasi pemangku kepentingan                        | 2.  Mendefinisikan tujuan projek dan ekspektasi pemangku kepentingan                                                     |
|                                                                                     |                                                                                                                          |
|                                                                                     | 3.  Membuat pertanyaan yang menjawab tujuan projek                                                                       |
+-------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| **Persiapan**                                                                       | 1.  Mengidentifikasi data yang dibutuhkan dan sumber data yang tersedia                                                  |
|                                                                                     |                                                                                                                          |
| Mempersiapkan data dan cara untuk menyelesaikan projek dengan baik dan benar        | 2.  Menggunakan teknik *ROCCC (Reliability, Origins, Comprehensiveness, Current relevance, and Credibility)* pada data   |
+-------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| **Proses**                                                                          | 1.  Membersihkan, mengurutkan dan memfilter data                                                                         |
|                                                                                     |                                                                                                                          |
| Menjalankan hasil persiapan dan menyiapkan data agar siap digunakan                 | 2.  Menggunakan *principle of data integrity*                                                                            |
|                                                                                     |                                                                                                                          |
|                                                                                     | 3.  Membuat dokumentasi dari pembersihan, pengurutan dan pemfilteran data                                                |
+-------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| **Analisa**                                                                         | 1.  Memahami data secara mendalam                                                                                        |
|                                                                                     |                                                                                                                          |
| Menganalisa data untuk menjawab tujuan projek                                       | 2.  Mengidentifikasi tren dan hubungan dalam data dalam menyelesaikan tujuan projek                                      |
|                                                                                     |                                                                                                                          |
|                                                                                     | 3.  Memvalidasi hasil analisa dengan pakar dibidangnya                                                                   |
|                                                                                     |                                                                                                                          |
|                                                                                     | 4.  Membuat visualisasi dari hasil analisa                                                                               |
+-------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| **Berbagi**                                                                         | Membuat laporan presentasi, dashboard dan laporan pelangkap lain dari hasil analisa                                      |
|                                                                                     |                                                                                                                          |
| Membagikan hasil analisa kepada pihak yang terkait                                  |                                                                                                                          |
+-------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+
| **Bertindak**                                                                       | Menerapkan hasil anlisa berupa temuan atau rekomendasi bersama pihak yang terkait untuk menjalankan projek sesuai tujuan |
|                                                                                     |                                                                                                                          |
| Bekerja dengan pemangku kepentingan untuk menerapkan cara terbaik dari hasil anlisa |                                                                                                                          |
+-------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------+

------------------------------------------------------------------------

------------------------------------------------------------------------

# [Bertanya]{.underline}

**Pandangan Awal:**

**Produk:** Layanan peminjaman/berbagi sepeda dengan jaringan di seluruh Chicago.

**Jenis Pelanggan dan Model Pendapatan:** anggota tahunan (langganan tahunan) dan pengendara kasual (pembelian sekali jalan dan harian).

**Keunggulan Bersaing:** Ragam jenis sepeda (segmentasi konsumen yang luas) dan fleksibilitas dalam penetapan harga.

Proses bertanya akan menghasilkan tujuan projek, tugas bisnis, ekspektasi pemangku kepentingan, pertanyaan untuk tujuan projek, timeline dan output yang akan dihasilkan dalam projek ini, semua hal tersebut dirangkum dalam dokumen ruang lingkup kerja, dokumen tersebut dapat diakses [disini](https://github.com/dhandiyy/cyclistic-analysis/blob/main/Scope%20Of%20Work-Cyclistic.pdf).

------------------------------------------------------------------------

------------------------------------------------------------------------

# [Persiapan]{.underline}

Saya akan menggunakan data perjalanan historis Cyclistic untuk menganalisis dan mengidentifikasi tren. Data yang digunakan berada dalam kurun waktu 12 bulan (Januari-Desember) pada tahun 2022, anda dapat melihat kumpulan datanya [disini](https://divvy-tripdata.s3.amazonaws.com/index.html). Data telah disediakan oleh Motivate International Inc, dengan [lisensi](https://ride.divvybikes.com/data-license-agreement) berikut.

Data yang digunakan disimpan dalam format *csv* yang dibagi per-bulan, nantinya data akan digabungkan untuk memudahkan dalam analisa.

Cek kuliatas data menggunakan prinsip *ROCCC:*

-   **Realiable** ⚠️

    Dari pengamatan awal terdapat records pada data yang tidak lengkap, memiliki duplikasi dan terdapat format yang tidak konsisten. Pengamatan ini akan saya bahas lebih jelas pada tahap proses.

-   **Original** ✔️

    Data yang digunakan berasal dari pihak pertama yaitu Motivate International Inc dan tidak menggunakan data dari pihak kedua maupun ketiga

-   **Comprehensif** ✔️

    Data yang digunakan sudah cukup lengkap untuk menjawab tugas bisnis dan tujuan projek, tapi hasil analisa akan lebih valid jika menambahkan data yang lebih banyak.

-   **Current** ✔️

    Data tergolong baru karena menggunakan data tahun lalu dan mempunyai informasi yang relevant

-   **Cited** ✔️

    Data dikutip dari pihak pertama

------------------------------------------------------------------------

------------------------------------------------------------------------

# [Proses]{.underline}

**Integritas dan Etika Data**

Data memiliki format yang benar pada setiap kolom, memiliki akurasi serta konsistensi pada sebagian besar data, serta memiliki keabsahan dan kelengkapan yang baik untuk menjawab tugas bisnis dan tujuan projek.

Data disimpan dalam cloud repository pihak pertama, dapat diakses secara publik, terbebas dari informasi pribadi pengguna dan memiliki lisensi yang terpercaya.

**Proses pembersihan data:**

Install package yang diperlukan

```{r load package, echo=TRUE}
library(tidyverse)
library(data.table)
```

Pengecekan awal data yang tersedia

```{r cek data awal}
# Mendapatkan jalur ke direktori script saat ini (Folder 1)
current_dir <- getwd()

# Buat jalur lengkap ke file CSV di dalam Folder 2
csv_path <- file.path(current_dir, "Dataset", "202201-divvy-tripdata.csv")

# Menggunakan data.table untuk membaca file CSV
data_example <- fread(csv_path)

head(data_example)

```

menggunakan fungsi lain untuk cek data

```{r cek data menggunakan fungsi lain}
glimpse(data_example)
```

```{r}
summary(data_example)
```

Pemahaman awal tentang data Data memiliki 13 kolom dengan berbagai tipe data

Menggabungkan beberapa dataset(csv) yang akan digunakan untuk anlisa, sebelum itu kita cek konsistensi kolom dan dimensi tiap dataset

```{r}
csv_folder <- file.path(current_dir, "Dataset")

# List semua file CSV dalam folder Anda 
csv_files <- list.files(path = csv_folder, pattern = "2022", full.names = TRUE)

# Loop melalui setiap file CSV dan tampilkan dimensinya
for (csv_file in csv_files) {
  # Membaca data CSV tanpa memuat seluruh data ke memori (metada)
  # karena nrows = 0
  data <- fread(csv_file, nrows = 0)
  
  # Mendapatkan dimensi
  dimensions <- dim(data)
  
  # Menampilkan nama file dan dimensi
  cat("File:", basename(csv_file), "\n")
  cat("Rows:", dimensions[1], "Columns:", dimensions[2], "\n\n")
}
```

Melakukan pengecekan nama kolom tiap data/file csv

```{r}
first_file_cols <- NULL 
check_difference <- FALSE
for (csv_file in csv_files){
  if (is.null(first_file_cols)){
    first_file_cols <- colnames(fread(csv_file))
  }else{
    current_cols <- colnames(fread(csv_file))
    if(!identical(first_file_cols, current_cols)){
      cat("Perbedaan nama kolom pada file:", csv_file, "\n")
      check_difference <- TRUE
    }
  }
}
#jika tidak ada perbedaan cetak:
if (!check_difference){
  cat("Semua file CSV memiliki nama kolom yang sama")
}
```

Gabungkan semua file ketika nama kolom sudah sama

```{r}
library(data.table)
combined_data <- data.table()

# Loop melalui setiap file CSV untuk menggabungkannya
for (csv_file in csv_files) {
  # Membaca data dari file CSV dan menggabungkannya dengan data yang sudah ada
  current_data <- fread(csv_file, na.strings = c("",NA))
  combined_data <- rbind(combined_data, current_data)
}

# Menyimpan data yang telah digabungkan ke dalam satu file CSV
fwrite(combined_data, "combined_data.csv")
```

cek kembali file yang sudah digabungkan

```{r}
dim.data.frame(combined_data)
```

Terdapat 5.667.717 records/baris dan 13 fields/kolom

```{r}
head(combined_data)
```

Lakukan pengecekan ulang saat semua data sudah digabungkan

ketika menggunakan fungsi `skimr_without_chart` menghasilkan nilai dibawah ini:

![](skimr.png){width="726"}

note: output fungsi tersebut tidak dapat ditampilkan jika menggunakan R Markdown

Terdapat missing value pada kolom **start_station_name, start_station_id, end_station_name, end_station_id** maksimal sebesar **16%** serta missing value juga terdapat pada kolom **end_lat** dan **end_lng** sebesar **1%**

Missing value pada baris yang hilang tidak akan dihapus karena kita akan gunakan informasi pada kolom yang lain pada baris tersebut

cek duplicate kolom ride_id yang menjadi primary key pada tabel yang digunakan sedangkan kolom yang identik dengan ride_id yaitu kolom start_station_id dan end_station_id bisa saja sama karena menjadi foreign key pada tabel.

```{r}

# Menghitung jumlah data yang duplicate pada kolom ride_id
duplicate_count_ride_id <- sum(duplicated(combined_data$ride_id))

# Output
print(paste0("Jumlah data duplicate pada kolom ride_id: ", duplicate_count_ride_id))
```

Cek apakah ada data yang tidak konsisten pada kolom `started_at` dan `ended_at`; selisih waktu menghasilkan nilai minus atau nol

```{r}
# Memeriksa konsistensi kolom
inconsistent_data <- combined_data %>%
  filter(started_at >= ended_at | started_at == ended_at)

# Output
if (nrow(inconsistent_data) > 0) {
  print("Terdapat data dengan konsistensi yang tidak sesuai.")
  print(inconsistent_data)
} else {
  print("Semua data dalam kolom waktu datang dan waktu pulang konsisten.")
}
```

Terdapat 531 baris yang tidak konsisten, baris tersebut akan dihapus karena butuh validasi lanjutan untuk memperbaiki baris tersebut dengan stakeholder

```{r}
data_cleaned <- combined_data %>%
  filter(started_at < ended_at, started_at != ended_at)

head(data_cleaned)
```

```{r}
dim.data.frame(data_cleaned)
```

cek apakah bisa mencari selisih waktu ketika kolom `started_at` dan `ended_at sudah diperbaiki`

```{r}
baris_pertama  <- data_cleaned[3, ]
selisih_waktu_ex <- baris_pertama$ended_at - baris_pertama$started_at
print(selisih_waktu_ex)
```

### Memperbaiki missing value

pertama, kita akan memisahkan dulu baris yang memiliki nilai NA menjadi tabel tersendiri agar kita dapat dengan mudah memprosesnya.

```{r}
data_cleaned_na <- data_cleaned %>%
  filter(is.na(start_station_name) | is.na(start_station_id) | is.na(end_station_name) | is.na(end_station_id) | is.na(end_lat) | is.na(end_lng))

str(data_cleaned_na)
```

```{r}
data_cleaned_na
```

Mencari missing value pada kolom `start_station_name` dengan cara memisahkan kolom `start_station_name`, `start_lat` dan `start_lng`, kita gunakan informasi yang berada pada kolom `start_lat` dan `start_lng` dengan harapan setian station name memiliki latitude dan longitude yang berpasangan , jika ini cara ini berhasil maka akan dilakukan juga untuk kolom end_station_name.

```{r}
tabel_distinct_ssn <- data_cleaned_na %>%
  select(start_station_name, start_lat, start_lng) %>%
  distinct(start_lat,start_lng, .keep_all = TRUE)
```

lihat hasil

```{r}
tabel_distinct_ssn
```

cek terdapat 1,577 rows ketika distinct menggunakan nama dan 420,803 rows ketika distinct menggunakan start_lat dan start_lng

```{r}
filtered_distinct_ssn <- tabel_distinct_ssn %>%
  filter(grepl("^41.95", start_lat) & grepl("^-87.65", start_lng))

filtered_distinct_ssn
```

Hasilnya tidak ditemukan pasangan data pada setiap record start_station_name dengan latitude dan longitudenya. Artinya, pendekatan ini tidak bisa digunakan untuk memperbaiki data yang hilang.

ketika data missing saya mencoba mencarinya tapi jika tidak ada seharusnya jika pada real life scenario, permasalahan ini bisa saya langsung tanyakan pada stakeholder/pihak yang terkait untuk mencari tahu apa yang terjadi pada data point ini atau apakah ada datasource lain yang bisa digunakan. Namun saya tidak punya akses untuk sumber daya seperti ini, jadi saya tetap mempertahankan data yang ada sehingga perhitungannya mungkin tetap benar jika mengacu pada *statiscal power*.

### Memperbaiki value agar lebih informatif dan mudah dibaca

```{r}
data_cleaned %>%
  select(rideable_type, member_casual) %>%
  distinct(rideable_type, member_casual)
```

```{r}
data_cleaned <- data_cleaned %>%
  mutate(rideable_type = case_when(
    rideable_type == "electric_bike" ~ "Electric Bike",
    rideable_type == "classic_bike" ~ "Classic Bike",
    rideable_type == "docked_bike" ~ "Docked Bike",
    TRUE ~ rideable_type  # Jika tidak ada perubahan, biarkan nilai asli
    ),
    member_casual = case_when(
      member_casual == "casual" ~ "Casual Member",
      member_casual == "member" ~ "Annual Member",
      TRUE ~ member_casual
    )
  )
```

Data sudah dapat kita proses.
